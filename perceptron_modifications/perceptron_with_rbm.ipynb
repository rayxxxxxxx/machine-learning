{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=10)\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "fig.set_dpi(150)\n",
    "\n",
    "nums_mtrx = np.loadtxt(Path('.', 'basic', 'numbers.txt'))\n",
    "\n",
    "for n, ax in zip(nums_mtrx, axes.ravel()):\n",
    "    ax.imshow(n.reshape(5, 3), cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_columns = [f'c{n}' for n in range(15)]\n",
    "classes = ['zero', 'one', 'two', 'three', 'four',\n",
    "           'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "df = pd.DataFrame(columns=cells_columns+['class'])\n",
    "\n",
    "for i in range(10):\n",
    "    new_row = dict(zip(cells_columns, nums_mtrx[i]))\n",
    "    new_row['class'] = classes[i]\n",
    "\n",
    "    df.loc[df.index.size] = new_row\n",
    "\n",
    "    for j in range(9):\n",
    "        noised_num = nums_mtrx[i] + np.random.uniform(0, 0.5, 15)\n",
    "\n",
    "        new_row = dict(zip(cells_columns, noised_num))\n",
    "        new_row['class'] = classes[i]\n",
    "\n",
    "        df.loc[df.index.size] = new_row\n",
    "\n",
    "for name in df['class'].unique():\n",
    "    df[f'{name}_label'] = df['class'].map(lambda x: 1 if x == name else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.7\n",
    "\n",
    "p = np.arange(10)\n",
    "\n",
    "test_size = int(p.size*test_frac)\n",
    "train_size = int(p.size*(1-test_frac))\n",
    "\n",
    "idx_test = np.ravel([(p[0: test_size] + i*10) for i in range(10)])\n",
    "idx_train = np.ravel([(p[test_size: p.size] + i*10) for i in range(10)])\n",
    "\n",
    "features_columns = cells_columns\n",
    "label_columns = [f\"{name}_label\" for name in classes]\n",
    "\n",
    "xTest = np.array(df.iloc[idx_test][features_columns])\n",
    "yTest = np.array(df.iloc[idx_test][label_columns])\n",
    "\n",
    "xTrain = np.array(df.iloc[idx_train][features_columns])\n",
    "yTrain = np.array(df.iloc[idx_train][label_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def F(x: np.ndarray) -> np.ndarray:\n",
    "    # return x\n",
    "    # return np.clip(x,-1, 1)\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def dF(x: np.ndarray) -> np.ndarray:\n",
    "    # return np.ones(x.shape)\n",
    "    # return np.array([0 if xi <= -1 or xi >= 1 else 1 for xi in x])\n",
    "    return 1-np.square(np.tanh(x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def relu(x: np.ndarray) -> np.ndarray:\n",
    "    return np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def dRelu(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 * (x > 0)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def dSigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y*(1-y)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    y = np.exp(x)\n",
    "    return y/np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def grads(xBatch: np.ndarray, yBatch: np.ndarray, Wh: np.ndarray, w: np.ndarray, Bh: np.ndarray, Bx: np.ndarray, b: np.ndarray) -> tuple[np.ndarray]:\n",
    "    dWh = np.zeros(Wh.shape)\n",
    "    dw = np.zeros(w.shape)\n",
    "\n",
    "    dBh = np.zeros(Bh.shape)\n",
    "    dBx = np.zeros(Bx.shape)\n",
    "    db = np.zeros(b.shape)\n",
    "\n",
    "    for i in prange(xBatch.shape[0]):\n",
    "        h = xBatch[i] @ Wh + Bh\n",
    "        z = sigmoid(h @ Wh.T + Bx)\n",
    "        y = softmax(z @ w + b)\n",
    "\n",
    "        dLdz = (y-yBatch[i]) @ w.T\n",
    "\n",
    "        dw += np.outer(z, y-yBatch[i])\n",
    "        db += y-yBatch[i]\n",
    "\n",
    "        dWh += np.outer(xBatch[i], dLdz * z*(1-z) @ Wh)\n",
    "        dBx += dLdz * z*(1-z)\n",
    "        dBh += dLdz * z*(1-z) @ Wh\n",
    "\n",
    "    return (dWh, dw, dBh, dBx, db)\n",
    "\n",
    "\n",
    "class RBMPerceptron:\n",
    "    def __init__(self, nH: int, nIn: int, nOut: int) -> None:\n",
    "        self.nH = nH\n",
    "        self.nIn = nIn\n",
    "        self.nOut = nOut\n",
    "\n",
    "        self.Wh: np.ndarray = np.random.uniform(-1, 1, (nIn, nH))\n",
    "        self.w: np.ndarray = np.random.uniform(-1, 1, (nIn, nOut))\n",
    "\n",
    "        self.Bh: np.ndarray = np.zeros(nH)\n",
    "        self.Bx: np.ndarray = np.zeros(nIn)\n",
    "        self.b: np.ndarray = np.zeros(nOut)\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        h = x @ self.Wh + self.Bh\n",
    "        z = h @ self.Wh.T + self.Bx\n",
    "        return softmax(sigmoid(z) @ self.w + self.b)\n",
    "\n",
    "    def train(self, xTrain: np.ndarray, yTrain: np.ndarray, lr, batch_size, max_epoch) -> None:\n",
    "        n = xTrain.shape[0]\n",
    "\n",
    "        for epoch in range(max_epoch):\n",
    "            idxs = np.random.choice(a=np.arange(\n",
    "                n), size=batch_size, replace=False)\n",
    "\n",
    "            for batch_idx in range(n//batch_size):\n",
    "                ibegin, iend = batch_idx * \\\n",
    "                    batch_size, min((batch_idx+1)*batch_size, n-1)\n",
    "                batch_idxs = idxs[ibegin:iend]\n",
    "\n",
    "                dWh, dw, dBh, dBx, db = grads(\n",
    "                    xTrain[batch_idxs], yTrain[batch_idxs], self.Wh, self.w, self.Bh, self.Bx, self.b)\n",
    "\n",
    "                self.Wh -= lr*dWh\n",
    "                self.w -= lr*dw\n",
    "\n",
    "                self.Bh -= lr*dBh\n",
    "                self.Bx -= lr*dBx\n",
    "                self.b -= lr*db\n",
    "\n",
    "    def loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        yPred = np.array([self.predict(xi) for xi in x])\n",
    "        h = -np.sum(y*np.log(yPred), axis=1)\n",
    "        return 1/x.shape[0] * np.sum(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained loss: 1.190275\n",
      "trained loss: 0.259933\n",
      "test set accuracy: 94.17%\n"
     ]
    }
   ],
   "source": [
    "nH = 16\n",
    "nIn = 4\n",
    "nOut = 3\n",
    "\n",
    "lr = 1e-2\n",
    "batch_size = 8\n",
    "max_epoch = 5000\n",
    "\n",
    "model = RBMPerceptron(nH, nIn, nOut)\n",
    "\n",
    "print('untrained loss: {0:.6f}'.format(model.loss(xTest, yTest)))\n",
    "\n",
    "model.train(xTrain, yTrain, lr, batch_size, max_epoch)\n",
    "\n",
    "print('trained loss: {0:.6f}'.format(model.loss(xTest, yTest)))\n",
    "\n",
    "TP_count = 0\n",
    "for x, y in zip(xTest, yTest):\n",
    "    yPred = model.predict(x)\n",
    "    TP_count += 1 if np.argmax(y) == np.argmax(yPred) else 0\n",
    "\n",
    "accuracy = TP_count / xTest.shape[0]\n",
    "print(f\"test set accuracy: {round(accuracy*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noised = nums_mtrx + np.random.uniform(0, 0.5, 15)\n",
    "\n",
    "yPred = list([model.predict(xi) for xi in x_noised])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=10)\n",
    "\n",
    "fig.set_dpi(100)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(x_noised[i].reshape((5, 3)),  cmap='gray')\n",
    "    j = np.argmax(yPred[i])\n",
    "    ax.set_title(f\"{j} : {(yPred[i][j]*100).round()}%\")\n",
    "\n",
    "plt.autoscale()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
