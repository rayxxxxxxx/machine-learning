{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nOuFBbijCnPi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abc=' !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
            "len_abc=95\n"
          ]
        }
      ],
      "source": [
        "abc = ' ' + string.punctuation + string.digits + string.ascii_letters\n",
        "len_abc = len(abc)\n",
        "print(f'{abc=}\\n{len_abc=}')\n",
        "\n",
        "itoc = {i:c for i,c in enumerate(abc)}\n",
        "ctoi = {c:i for i,c in enumerate(abc)}\n",
        "\n",
        "def encode(s: str) -> list[int]:\n",
        "\treturn [ctoi[c] for c in s]\n",
        "\n",
        "def decode(l: list[int]) -> str:\n",
        "\treturn ''.join([itoc[i] for i in l])\n",
        "\n",
        "def enc2tnsr(l: list[int]) -> torch.Tensor:\n",
        "\treturn torch.tensor(l).long()\n",
        "\n",
        "def enc2seq(l: list[int]) -> torch.Tensor:\n",
        "\treturn F.one_hot(enc2tnsr(l), len_abc).float()\n",
        "\n",
        "def tnsr2seq(t: torch.Tensor) -> torch.Tensor:\n",
        "\treturn F.one_hot(t, len_abc).float()\n",
        "\n",
        "def str2seq(s: str) -> torch.Tensor:\n",
        "\tencoded = torch.tensor(encode(s)).long()\n",
        "\treturn F.one_hot(encoded, len_abc).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dMmVk4WcxNKD"
      },
      "outputs": [],
      "source": [
        "class WriteHead(nn.Module):\n",
        "\tdef __init__(self, in_dim, n_mem, mem_dim, key_dim) -> None:\n",
        "\t\tsuper(WriteHead, self).__init__()\n",
        "\n",
        "\t\tself.scale = key_dim**(-0.5)\n",
        "\n",
        "\t\tself.q = nn.Linear(mem_dim, key_dim, bias=False)\n",
        "\t\tself.k = nn.Linear(in_dim, key_dim, bias=False)\n",
        "\t\tself.v = nn.Linear(in_dim, mem_dim, bias=False)\n",
        "\t\tself.G = nn.Parameter(torch.rand(mem_dim, n_mem))\n",
        "\t\tself.U = nn.Parameter(torch.rand(key_dim, key_dim))\n",
        "\t\n",
        "\tdef forward(self, x: torch.Tensor, M: torch.Tensor) -> torch.Tensor:\n",
        "\t\t# print('// WRITE HEAD')\n",
        "\t\t# print(f'{x.shape=} {M.shape=}')\n",
        "\t\tQ, K, V = self.q(M), self.k(x), self.v(x)#; print(f'{Q.shape=} {K.shape=} {V.shape=}')\n",
        "\t\tA = F.softmax(Q @ self.U @ K.transpose(-1,-2) * self.scale, dim=-2)#; print(f'{A.shape=}')\n",
        "\t\tG = F.sigmoid(V @ self.G @ M)#; print(f'{G.shape=}')\n",
        "\t\treturn A @ (G * V)\n",
        "\n",
        "\n",
        "class ReadHead(nn.Module):\n",
        "\tdef __init__(self, in_dim, n_mem, mem_dim, key_dim) -> None:\n",
        "\t\tsuper(ReadHead, self).__init__()\n",
        "\n",
        "\t\tself.scale = key_dim**(-0.5)\n",
        "\n",
        "\t\tself.q = nn.Linear(in_dim, key_dim, bias=False)\n",
        "\t\tself.k = nn.Linear(mem_dim, key_dim, bias=False)\n",
        "\t\tself.v = nn.Linear(mem_dim, in_dim, bias=False)\n",
        "\t\tself.G = nn.Parameter(torch.rand(in_dim, n_mem))\n",
        "\t\tself.U = nn.Parameter(torch.rand(key_dim, key_dim))\n",
        "\n",
        "\tdef forward(self, x: torch.Tensor, M: torch.Tensor) -> torch.Tensor:\n",
        "\t\t# print('// READ HEAD')\n",
        "\t\t# print(f'{x.shape=} {M.shape=}')\n",
        "\t\tQ, K, V = self.q(x), self.k(M), self.v(M)#; print(f'{Q.shape=} {K.shape=} {V.shape=}')\n",
        "\t\tA = F.softmax(Q @ self.U @ K.transpose(-1,-2) * self.scale, dim=-1)#; print(f'{A.shape=}')\n",
        "\t\tG = F.sigmoid(x @ self.G @ V)#; print(f'{G.shape=}')\n",
        "\t\treturn torch.sum(A @ (G * V), dim=-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k_zbPTs6t8Oz"
      },
      "outputs": [],
      "source": [
        "class WriteBlock(nn.Module):\n",
        "\tdef __init__(self, in_dim, n_mem, mem_dim, key_dim, n_heads) -> None:\n",
        "\t\tsuper(WriteBlock, self).__init__()\n",
        "\n",
        "\t\tself.heads = nn.ModuleList([WriteHead(in_dim, n_mem, mem_dim, key_dim//n_heads) for _ in range(n_heads)])\n",
        "\t\tself.proj = nn.Linear(n_heads*mem_dim, mem_dim)\n",
        "\n",
        "\tdef forward(self, x: torch.Tensor, M: torch.Tensor) -> torch.Tensor:\n",
        "\t\tM_w = [head(x, M) for head in self.heads]\n",
        "\t\treturn self.proj(torch.cat(M_w, dim=-1))\n",
        "\n",
        "\n",
        "class ReadBlock(nn.Module):\n",
        "\tdef __init__(self, in_dim, n_mem, mem_dim, key_dim, n_heads) -> None:\n",
        "\t\tsuper(ReadBlock, self).__init__()\n",
        "\n",
        "\t\tself.heads = nn.ModuleList([ReadHead(in_dim, n_mem, mem_dim, key_dim//n_heads) for _ in range(n_heads)])\n",
        "\t\tself.proj = nn.Linear(n_heads*in_dim, in_dim)\n",
        "\n",
        "\tdef forward(self, x: torch.Tensor, M: torch.Tensor) -> torch.Tensor:\n",
        "\t\tM_r = [head(x, M) for head in self.heads]\n",
        "\t\treturn self.proj(torch.cat(M_r, dim=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Memory(nn.Module):\n",
        "\tdef __init__(self, in_dim, n_mem, mem_dim, key_dim, n_heads) -> None:\n",
        "\t\tsuper(Memory, self).__init__()\n",
        "\n",
        "\t\tself.register_buffer('M', torch.rand(1, n_mem, mem_dim))\n",
        "\t\tself.writer = WriteBlock(in_dim, n_mem, mem_dim, key_dim, n_heads)\n",
        "\t\tself.reader = ReadBlock(in_dim, n_mem, mem_dim, key_dim, n_heads)\n",
        "\n",
        "\tdef reset_memory(self) -> None:\n",
        "\t\tself.M = torch.rand(1, *self.M.shape[1:])\n",
        "\t\tnn.init.xavier_uniform_(self.M)\n",
        "\n",
        "\tdef forward(self, x: torch.Tensor, op: str) -> torch.Tensor | None:\n",
        "\t\tif x.ndim == 2:\n",
        "\t\t\tx = x.unsqueeze(0)\n",
        "\n",
        "\t\tif op == 'w':\n",
        "\t\t\tself.M = self.M + self.writer(x, self.M)\n",
        "\t\telif op == 'r':\n",
        "\t\t\tx = x.transpose(0, 1)\n",
        "\t\t\treturn self.reader(x, self.M)\n",
        "\t\treturn None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size: 67283\n"
          ]
        }
      ],
      "source": [
        "IN_DIM = len_abc\n",
        "N_MEM = 32\n",
        "MEM_DIM = 16\n",
        "KEY_DIM = 16\n",
        "N_HEADS = 4\n",
        "\n",
        "mem = Memory(IN_DIM, N_MEM, MEM_DIM, KEY_DIM, N_HEADS)\n",
        "print('model size:', sum([p.numel() for p in mem.parameters()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "txt = 'The quick brown fox jumps over the lazy dog.'\n",
        "encoded = encode(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "mem.M.shape=torch.Size([1, 32, 16])\n"
          ]
        }
      ],
      "source": [
        "# WRITING: UNBATCHED INPUT\n",
        "\n",
        "mem.reset_memory()\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "seq = enc2seq(encoded)\n",
        "mem.forward(seq, op='w')\n",
        "print(f'{mem.M.shape=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "mem.M.shape=torch.Size([64, 32, 16])\n"
          ]
        }
      ],
      "source": [
        "# WRITING: BATCHED INPUT\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "mem.reset_memory()\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "seq = enc2seq(encoded)\n",
        "seq = seq.expand(BATCH_SIZE, *seq.shape)\n",
        "mem.forward(seq, op='w')\n",
        "print(f'{mem.M.shape=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "m_r.shape=torch.Size([1, 95])\n"
          ]
        }
      ],
      "source": [
        "# READING: UNBATCHED INPUT\n",
        "\n",
        "mem.reset_memory()\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "x = torch.rand(1, IN_DIM)\n",
        "m_r = mem.forward(x, op='r')\n",
        "\n",
        "print(f'{m_r.shape=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "m_r.shape=torch.Size([64, 95])\n"
          ]
        }
      ],
      "source": [
        "# READING: BATCHED INPUT\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "mem.reset_memory()\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "x = torch.rand(BATCH_SIZE, IN_DIM)\n",
        "m_r = mem.forward(x, op='r')\n",
        "\n",
        "print(f'{m_r.shape=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "m_r.shape=torch.Size([1, 95])\n"
          ]
        }
      ],
      "source": [
        "# WRITE THAN READ THAN BACKWARD(): UNBATCHED INPUT\n",
        "\n",
        "mem.reset_memory()\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "seq = enc2seq(encoded)\n",
        "mem.forward(seq, op='w')\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "x = torch.rand(1, IN_DIM)\n",
        "m_r = mem.forward(x, op='r')\n",
        "print(f'{m_r.shape=}')\n",
        "\n",
        "m_r.sum().backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mem.M.shape=torch.Size([1, 32, 16])\n",
            "mem.M.shape=torch.Size([64, 32, 16])\n",
            "m_r.shape=torch.Size([64, 95])\n"
          ]
        }
      ],
      "source": [
        "# WRITE THAN READ THAN BACKWARD(): BATCHED INPUT\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "mem.reset_memory()\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "seq = enc2seq(encoded)\n",
        "batch = seq.expand(BATCH_SIZE, *seq.shape)\n",
        "mem.forward(batch, op='w')\n",
        "print(f'{mem.M.shape=}')\n",
        "\n",
        "x = torch.rand(BATCH_SIZE, IN_DIM)\n",
        "m_r = mem.forward(x, op='r')\n",
        "print(f'{m_r.shape=}')\n",
        "\n",
        "m_r.sum().backward()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
