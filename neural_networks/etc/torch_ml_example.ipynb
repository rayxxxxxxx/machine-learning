{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dsy7TBhOwLTP"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as tfunc\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"using: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HV4FmEgwlJr",
        "outputId": "d957a663-8800-4569-f9d5-9c45d3406412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(n, i):\n",
        "    q = np.zeros(n)\n",
        "    q[i] = 1.0\n",
        "    return q\n",
        "\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, fp):\n",
        "\n",
        "        xy = np.loadtxt(fp, delimiter=',', dtype=np.float32)\n",
        "\n",
        "        self.x = torch.from_numpy(xy[:, 1:])\n",
        "        self.x = self.x / 255.0\n",
        "\n",
        "        labels = []\n",
        "        for i in xy[:, 0]:\n",
        "            labels.append(one_hot(10, int(i)))\n",
        "\n",
        "        self.y = torch.from_numpy(np.array(labels))\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "FOqp_fNSYPbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNISTDataset(Path('/content/sample_data/mnist_train_small.csv'))\n",
        "test_dataset = MNISTDataset(Path('/content/sample_data/mnist_test.csv'))"
      ],
      "metadata": {
        "id": "LidSecGmZTnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size)"
      ],
      "metadata": {
        "id": "N9imMsimdq7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, n_in, n_hidden, n_out):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_in = n_in\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_out = n_out\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.n_in, self.n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.n_hidden, self.n_out),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        y = self.classifier(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "gwAQCNdC8Ig_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    for (x, y) in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        y_predicted = model(x)\n",
        "\n",
        "        loss = loss_fn(y_predicted, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "h1WEdfCC-B7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    nbatches = len(dataloader)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss = 0\n",
        "    true_positive = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (x, y) in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            y_predicted = model(x)\n",
        "\n",
        "            loss += loss_fn(y_predicted, y).item()\n",
        "            true_positive += (y_predicted.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "\n",
        "    return (loss / nbatches, true_positive / size)\n",
        "\n"
      ],
      "metadata": {
        "id": "SvUOBg3G_Pzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 16\n",
        "learn_ing_rate = 1e-2"
      ],
      "metadata": {
        "id": "i6JITgOno3i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_in = 784\n",
        "n_hidden = 16\n",
        "n_out = 10\n",
        "\n",
        "model = Perceptron(n_in, n_hidden, n_out).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "-_PEq2iBo2ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n_epoch):\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    loss, acc = test(test_dataloader, model, loss_fn)\n",
        "    print(f\"Epoch: {i+1}; loss: {round(loss, 3)}; accuracy: {round(acc * 100, 4)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvkZGut5BBvz",
        "outputId": "6cfa3d58-8fbe-48e7-b143-74008cc663cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1; loss: 1.798; accuracy: 76.66%\n",
            "Epoch: 2; loss: 1.672; accuracy: 83.04%\n",
            "Epoch: 3; loss: 1.646; accuracy: 83.76%\n",
            "Epoch: 4; loss: 1.634; accuracy: 84.3%\n",
            "Epoch: 5; loss: 1.628; accuracy: 84.52%\n",
            "Epoch: 6; loss: 1.624; accuracy: 84.68%\n",
            "Epoch: 7; loss: 1.596; accuracy: 88.69%\n",
            "Epoch: 8; loss: 1.569; accuracy: 90.73%\n",
            "Epoch: 9; loss: 1.561; accuracy: 91.27%\n",
            "Epoch: 10; loss: 1.556; accuracy: 91.74%\n",
            "Epoch: 11; loss: 1.553; accuracy: 91.86%\n",
            "Epoch: 12; loss: 1.551; accuracy: 92.01%\n",
            "Epoch: 13; loss: 1.549; accuracy: 92.16%\n",
            "Epoch: 14; loss: 1.547; accuracy: 92.22%\n",
            "Epoch: 15; loss: 1.546; accuracy: 92.33%\n",
            "Epoch: 16; loss: 1.545; accuracy: 92.45%\n"
          ]
        }
      ]
    }
  ]
}