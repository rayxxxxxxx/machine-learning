{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x: np.ndarray) -> float:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def dF(x: np.ndarray) -> float:\n",
    "    return F(x)*(1-F(x))\n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self, nIn: int, nOut: int) -> None:\n",
    "        self.w: np.ndarray = np.random.uniform(-1, 1, (nIn, nOut))\n",
    "        self.b: np.ndarray = np.zeros((nOut))\n",
    "\n",
    "\n",
    "    def predict(self, x:np.ndarray) -> np.ndarray:\n",
    "        return F(np.dot(x, self.w)+self.b)\n",
    "\n",
    "\n",
    "    def train(self, xTrain: np.ndarray, yTrain: np.ndarray, lr, batch_size, max_iter) -> None:\n",
    "        n = xTrain.shape[0]\n",
    "\n",
    "        dw = np.zeros(self.w.shape)\n",
    "        db = np.zeros(self.b.shape)\n",
    "\n",
    "        for k in range(max_iter):\n",
    "            idxs = np.random.choice(a=np.arange(n), size=batch_size, replace=False)\n",
    "\n",
    "            for i in idxs:\n",
    "                dwi, dbi = self.grads(xTrain[i], yTrain[i])\n",
    "                dw += dwi\n",
    "                db += dbi\n",
    "            \n",
    "            self.w -= lr*dw\n",
    "            self.b -= lr*db\n",
    "\n",
    "            dw *= 0\n",
    "            db *= 0\n",
    "            \n",
    "\n",
    "    def grads(self, x: np.ndarray, y: np.ndarray) -> tuple[np.ndarray]:\n",
    "        u = np.dot(x, self.w)+self.b\n",
    "        a = F(u)\n",
    "\n",
    "        dEdu = 2*(a-y)*dF(u)\n",
    "        dEdw = dEdu*np.atleast_2d(x).T\n",
    "        dEdb = dEdu\n",
    "        \n",
    "        return dEdw, dEdb\n",
    "        \n",
    "    \n",
    "    def loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        n, m = y.shape[0], y[0].size\n",
    "        \n",
    "        u = np.array([self.predict(xi) for xi in x])\n",
    "        d = np.array([1/m * np.sum(np.square(ui-yi)) for ui, yi in zip(u, y)])\n",
    "        \n",
    "        return 1/n*np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('..', 'data', 'iris_csv.csv'))\n",
    "\n",
    "class_mapping = {\n",
    "    'Iris-setosa':0,\n",
    "    'Iris-versicolor':0.5,\n",
    "    'Iris-virginica':1\n",
    "}\n",
    "\n",
    "for name in df['class'].unique():\n",
    "    df[f'y_{name}'] = df['class'].map(lambda x: 1 if x == name else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.8\n",
    "\n",
    "p = np.random.permutation(df.index.size)\n",
    "\n",
    "idx_train = p[int(p.size*test_size):]\n",
    "idx_test = p[:int(p.size*test_size)]\n",
    "\n",
    "xTrain = np.array(df.iloc[idx_train, 0:4])\n",
    "yTrain = np.array(df.iloc[idx_train, 5:])\n",
    "\n",
    "xTest = np.array(df.iloc[idx_test, 0:4])\n",
    "yTest = np.array(df.iloc[idx_test, 5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained loss:  0.47566985097169867\n",
      "trained loss:  0.07783338340674685\n"
     ]
    }
   ],
   "source": [
    "nIn = 4\n",
    "nOut = 3\n",
    "\n",
    "lr = 1e-2\n",
    "batch_size = 10\n",
    "max_iter = 1000\n",
    "\n",
    "model = NNClassifier(nIn, nOut)\n",
    "\n",
    "print('untrained loss: ', model.loss(xTest, yTest))\n",
    "\n",
    "model.train(xTrain, yTrain, lr, batch_size, max_iter)\n",
    "\n",
    "print('trained loss: ', model.loss(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97 0.07 0.  ] [1 0 0]\n",
      "[0.   0.37 0.74] [0 0 1]\n",
      "[0.   0.18 0.89] [0 0 1]\n",
      "[0.   0.66 0.87] [0 0 1]\n",
      "[0.92 0.16 0.  ] [1 0 0]\n",
      "[0.03 0.56 0.43] [0 1 0]\n",
      "[0.   0.33 0.9 ] [0 0 1]\n",
      "[0.   0.24 0.82] [0 0 1]\n",
      "[0.87 0.17 0.  ] [1 0 0]\n",
      "[0.96 0.09 0.  ] [1 0 0]\n",
      "[0.01 0.3  0.51] [0 1 0]\n",
      "[0.02 0.39 0.4 ] [0 1 0]\n",
      "[0.88 0.1  0.  ] [1 0 0]\n",
      "[0.   0.74 0.98] [0 0 1]\n",
      "[0.01 0.34 0.64] [0 0 1]\n",
      "[0.95 0.12 0.  ] [1 0 0]\n",
      "[0.   0.31 0.81] [0 0 1]\n",
      "[0.   0.38 0.92] [0 0 1]\n",
      "[0.01 0.7  0.82] [0 0 1]\n",
      "[0.91 0.23 0.  ] [1 0 0]\n",
      "[0.92 0.22 0.  ] [1 0 0]\n",
      "[0.   0.66 0.89] [0 0 1]\n",
      "[0.01 0.36 0.83] [0 0 1]\n",
      "[0.17 0.38 0.09] [0 1 0]\n",
      "[0.87 0.16 0.  ] [1 0 0]\n",
      "[0.   0.73 0.95] [0 0 1]\n",
      "[0.9  0.19 0.  ] [1 0 0]\n",
      "[0.01 0.47 0.69] [0 0 1]\n",
      "[0.94 0.25 0.  ] [1 0 0]\n",
      "[0.   0.41 0.86] [0 0 1]\n",
      "[0.05 0.37 0.21] [0 1 0]\n",
      "[0.   0.23 0.87] [0 0 1]\n",
      "[0.   0.43 0.9 ] [0 0 1]\n",
      "[0.02 0.51 0.46] [0 1 0]\n",
      "[0.88 0.4  0.  ] [1 0 0]\n",
      "[0.04 0.32 0.23] [0 1 0]\n",
      "[0.05 0.42 0.15] [0 1 0]\n",
      "[0.02 0.41 0.34] [0 1 0]\n",
      "[0.94 0.19 0.  ] [1 0 0]\n",
      "[0.98 0.09 0.  ] [1 0 0]\n",
      "[0.95 0.13 0.  ] [1 0 0]\n",
      "[0.03 0.69 0.41] [0 1 0]\n",
      "[0.02 0.67 0.6 ] [0 1 0]\n",
      "[0.01 0.41 0.64] [0 0 1]\n",
      "[0.   0.51 0.77] [0 0 1]\n",
      "[0.96 0.13 0.  ] [1 0 0]\n",
      "[0.08 0.72 0.24] [0 1 0]\n",
      "[0.03 0.34 0.35] [0 1 0]\n",
      "[0.94 0.11 0.  ] [1 0 0]\n",
      "[0.03 0.42 0.26] [0 1 0]\n",
      "[0.87 0.1  0.  ] [1 0 0]\n",
      "[0.15 0.49 0.09] [0 1 0]\n",
      "[0.   0.31 0.84] [0 0 1]\n",
      "[0.01 0.29 0.64] [0 0 1]\n",
      "[0.   0.23 0.89] [0 0 1]\n",
      "[0.92 0.17 0.  ] [1 0 0]\n",
      "[0.94 0.16 0.  ] [1 0 0]\n",
      "[0.94 0.09 0.  ] [1 0 0]\n",
      "[0.93 0.25 0.  ] [1 0 0]\n",
      "[0.03 0.33 0.22] [0 1 0]\n",
      "[0.97 0.05 0.  ] [1 0 0]\n",
      "[0.03 0.59 0.34] [0 1 0]\n",
      "[0.04 0.45 0.16] [0 1 0]\n",
      "[0.   0.68 0.91] [0 0 1]\n",
      "[0.03 0.32 0.27] [0 1 0]\n",
      "[0.93 0.1  0.  ] [1 0 0]\n",
      "[0.06 0.5  0.23] [0 1 0]\n",
      "[0.01 0.25 0.57] [0 1 0]\n",
      "[0.9  0.23 0.  ] [1 0 0]\n",
      "[0.07 0.44 0.17] [0 1 0]\n",
      "[0.96 0.19 0.  ] [1 0 0]\n",
      "[0.04 0.4  0.26] [0 1 0]\n",
      "[0.94 0.26 0.  ] [1 0 0]\n",
      "[0.07 0.53 0.18] [0 1 0]\n",
      "[0.   0.3  0.89] [0 0 1]\n",
      "[0.02 0.22 0.27] [0 1 0]\n",
      "[0.01 0.44 0.5 ] [0 1 0]\n",
      "[0.02 0.47 0.3 ] [0 1 0]\n",
      "[0.95 0.14 0.  ] [1 0 0]\n",
      "[0.01 0.53 0.81] [0 0 1]\n",
      "[0.9  0.14 0.  ] [1 0 0]\n",
      "[0.   0.5  0.83] [0 0 1]\n",
      "[0.94 0.25 0.  ] [1 0 0]\n",
      "[0.02 0.45 0.42] [0 1 0]\n",
      "[0.11 0.5  0.17] [0 1 0]\n",
      "[0.   0.49 0.87] [0 0 1]\n",
      "[0.   0.37 0.74] [0 0 1]\n",
      "[0.03 0.5  0.36] [0 1 0]\n",
      "[0.   0.41 0.86] [0 0 1]\n",
      "[0.05 0.47 0.18] [0 1 0]\n",
      "[0.01 0.62 0.64] [0 1 0]\n",
      "[0.   0.41 0.81] [0 0 1]\n",
      "[0.   0.32 0.79] [0 0 1]\n",
      "[0.   0.33 0.85] [0 0 1]\n",
      "[0.91 0.2  0.  ] [1 0 0]\n",
      "[0.02 0.29 0.32] [0 1 0]\n",
      "[0.94 0.25 0.  ] [1 0 0]\n",
      "[0.   0.26 0.92] [0 0 1]\n",
      "[0.92 0.15 0.  ] [1 0 0]\n",
      "[0.   0.42 0.92] [0 0 1]\n",
      "[0.97 0.16 0.  ] [1 0 0]\n",
      "[0.11 0.45 0.16] [0 1 0]\n",
      "[0.92 0.12 0.  ] [1 0 0]\n",
      "[0.   0.44 0.91] [0 0 1]\n",
      "[0.03 0.54 0.38] [0 1 0]\n",
      "[0.09 0.56 0.18] [0 1 0]\n",
      "[0.07 0.46 0.18] [0 1 0]\n",
      "[0.92 0.27 0.  ] [1 0 0]\n",
      "[0.   0.66 0.85] [0 0 1]\n",
      "[0.93 0.09 0.  ] [1 0 0]\n",
      "[0.94 0.17 0.  ] [1 0 0]\n",
      "[0.   0.36 0.66] [0 0 1]\n",
      "[0.   0.62 0.94] [0 0 1]\n",
      "[0.   0.18 0.83] [0 0 1]\n",
      "[0.97 0.08 0.  ] [1 0 0]\n",
      "[0.01 0.32 0.62] [0 0 1]\n",
      "[0.02 0.45 0.42] [0 1 0]\n",
      "[0.   0.53 0.88] [0 0 1]\n",
      "[0.94 0.18 0.  ] [1 0 0]\n",
      "[0.07 0.53 0.23] [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(xTest, yTest):\n",
    "    print(model.predict(x).round(2), y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
