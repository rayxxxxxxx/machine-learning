{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AdhE9QnqEprw"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpfFHtKC98KE",
        "outputId": "b785dbc2-fd66-4af2-e20b-d29aab7d8ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
          ]
        }
      ],
      "source": [
        "abc = ' ' + string.punctuation + string.digits + string.ascii_letters\n",
        "len_abc = len(abc)\n",
        "\n",
        "itoc = {i:c for i,c in enumerate(abc)}\n",
        "ctoi = {c:i for i,c in enumerate(abc)}\n",
        "\n",
        "print(len_abc, abc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rtQq_c0P-eoi"
      },
      "outputs": [],
      "source": [
        "def encode(s: str) -> list[int]:\n",
        "    return [ctoi[c] for c in s]\n",
        "\n",
        "def decode(l: list[int]) -> str:\n",
        "    return ''.join([itoc[i] for i in l])\n",
        "\n",
        "def str2seq(s: str) -> torch.Tensor:\n",
        "    encoded = torch.tensor(encode(s)).long()\n",
        "    return F.one_hot(encoded, len_abc).float()\n",
        "\n",
        "def seq2str(s: torch.Tensor) -> str:\n",
        "    encoded = [torch.argmax(t).int().item() for t in s]\n",
        "    return decode(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X443BlDJEx-l"
      },
      "outputs": [],
      "source": [
        "rnn = nn.RNN(len_abc, 8, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jbldsBOl_BCd"
      },
      "outputs": [],
      "source": [
        "text = 'the quick brown fox jumps over the lazy dog'\n",
        "sequence = str2seq(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIHKxPWjzo7V",
        "outputId": "bdd322bd-0fd8-4477-9bee-9f747d38e985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8])\n",
            "torch.Size([43, 8])\n"
          ]
        }
      ],
      "source": [
        "states, context = rnn(sequence)\n",
        "\n",
        "print(context.shape)\n",
        "print(states.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jQ7rdLT1zjdu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 43, 95])\n"
          ]
        }
      ],
      "source": [
        "text1 = 'the quick brown fox jumps over the lazy dog'\n",
        "text2 = 'god yzal eht revo spmuj xof nworb kciuq eht'\n",
        "batch = torch.stack([str2seq(text1), str2seq(text2)])\n",
        "print(batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNa0_gFj76xC",
        "outputId": "d7751f3c-4c9b-4660-cfcc-fe82563d20e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 43, 8])\n",
            "torch.Size([1, 2, 8])\n"
          ]
        }
      ],
      "source": [
        "states, context = rnn(batch)\n",
        "\n",
        "print(states.shape)\n",
        "print(context.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QEUj667l0KHu"
      },
      "outputs": [],
      "source": [
        "def calculate_attention(x: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "    scores = F.softmax(x @ m, dim=1)\n",
        "    values = scores.unsqueeze(1) * m\n",
        "    return torch.sum(values, dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IPZBRT57qpLH"
      },
      "outputs": [],
      "source": [
        "text = 'the quick brown fox jumps over the lazy dog'\n",
        "sequence = str2seq(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sjY2PkMFh_A",
        "outputId": "7cf9a95a-4de9-4cd0-99fe-9663b2ce4a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
          ]
        }
      ],
      "source": [
        "n_hidden = 64\n",
        "\n",
        "encoder_rnn = nn.RNN(len_abc, n_hidden)\n",
        "decoder_rnn = nn.RNN(len_abc, n_hidden)\n",
        "final = nn.Linear(2*n_hidden, len_abc)\n",
        "\n",
        "states, context = encoder_rnn(sequence)\n",
        "\n",
        "outputs = []\n",
        "out = torch.zeros(1, len_abc)\n",
        "\n",
        "for i in range(128):\n",
        "    _, context = decoder_rnn(out, context)\n",
        "    attention = calculate_attention(context, states.T)\n",
        "    ctx_att = torch.cat((context, attention), dim=1)\n",
        "    out = F.softmax(final(ctx_att), dim=1)\n",
        "    outputs.append(out)\n",
        "\n",
        "outputs = torch.stack(outputs).squeeze(1)\n",
        "print(seq2str(outputs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
