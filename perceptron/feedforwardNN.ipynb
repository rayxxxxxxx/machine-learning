{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def F(x: np.ndarray) -> float:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "@njit\n",
    "def dF(x: np.ndarray) -> float:\n",
    "    return F(x)*(1-F(x))\n",
    "\n",
    "\n",
    "@njit\n",
    "def Fh(x: np.ndarray) -> float:\n",
    "    return x\n",
    "\n",
    "\n",
    "@njit\n",
    "def dFh(x: np.ndarray) -> float:\n",
    "    return np.sign(x)\n",
    "\n",
    "\n",
    "# @njit\n",
    "def back_prop(dEdw:np.ndarray, u: np.ndarray, z:np.ndarray) -> np.ndarray:\n",
    "    dEdul = np.sum(dEdw,axis=1)*dF(u)\n",
    "    dEdwl = dEdul*np.atleast_2d(z).T\n",
    "\n",
    "    return dEdwl\n",
    "\n",
    "# @njit\n",
    "# def back_prop(x: np.ndarray, y: np.ndarray, w: list[np.ndarray]) -> list[np.ndarray]:\n",
    "#     nl = len(w)\n",
    "#     l = len(w)\n",
    "    \n",
    "#     u = [x]\n",
    "#     a = [x]\n",
    "    \n",
    "#     dEdw = []\n",
    "\n",
    "#     uli = x.copy()\n",
    "    \n",
    "#     for i in range(nl):\n",
    "#         uli = uli@w[i]\n",
    "        \n",
    "#         u.append(uli)\n",
    "#         a.append(F(uli))\n",
    "\n",
    "#     dEdul = (a[l]-y)*dF(u[l])\n",
    "#     dEdwl = dEdul*np.atleast_2d(a[l-1]).T\n",
    "\n",
    "#     dEdw.append(dEdwl)\n",
    "\n",
    "#     l -= 1\n",
    "    \n",
    "#     while l > 0:\n",
    "#         dEdul = np.sum(dEdwl,axis=1)*dF(u[l])\n",
    "#         dEdwl = dEdul*np.atleast_2d(a[l-1]).T\n",
    "\n",
    "#         dEdw.append(dEdwl)\n",
    "        \n",
    "#         l -= 1\n",
    "    \n",
    "#     return dEdw\n",
    "\n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self, shape: tuple) -> None:\n",
    "        self.shape = shape\n",
    "        self.nIn = shape[0]\n",
    "        self.nOut = shape[-1]\n",
    "        \n",
    "        self.w: list[np.ndarray] = list()\n",
    "        self.b: list[np.ndarray] = list()\n",
    "\n",
    "        for i in range(len(shape)-1):\n",
    "            self.w.append(np.random.uniform(-1, 1, (shape[i], shape[i+1])))\n",
    "\n",
    "        for i in range(len(shape)-1):\n",
    "            self.b.append(np.zeros(shape[i+1]))\n",
    "\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        y = x.copy()\n",
    "        \n",
    "        for i in range(len(self.w)):\n",
    "            y = F(y@self.w[i])\n",
    "            \n",
    "        return y\n",
    "\n",
    "\n",
    "    def train(self, xTrain: np.ndarray, yTrain: np.ndarray, lr, batch_size, max_iter) -> None:\n",
    "        n = xTrain.shape[0]\n",
    "\n",
    "        dwh = list([np.zeros(wi.shape) for wi in self.w])\n",
    "\n",
    "        for k in range(max_iter):\n",
    "            idxs = np.random.choice(a=np.arange(n), size=batch_size, replace=False)\n",
    "\n",
    "            for i in idxs:\n",
    "                u = [xTrain[i]]\n",
    "                z = [xTrain[i]]\n",
    "                \n",
    "                uu = xTrain[i].copy()\n",
    "                for j in range(len(self.w)):\n",
    "                    uu = uu@self.w[j]\n",
    "                    u.append(uu)\n",
    "                    z.append(F(uu))\n",
    "                \n",
    "                dwl = np.atleast_2d(2*(z[-1]-yTrain[i]))\n",
    "                for j in reversed(range(len(self.w))):\n",
    "                    dwl = back_prop(dwl, u[j], z[j-1])\n",
    "                    dwh[j] = dwl.copy()\n",
    "                \n",
    "            for j in range(len(self.w)):\n",
    "                self.w[j] -= lr*dwh[j]\n",
    "                dwh[j] *= 0\n",
    "    \n",
    "\n",
    "    def back_prop(self, x: np.ndarray, y: np.ndarray) -> tuple[np.ndarray]:\n",
    "        u = [x]\n",
    "        a = [x]\n",
    "        \n",
    "        dEdw = list()\n",
    "        dEdb = list()\n",
    "\n",
    "        uli = x.copy()\n",
    "        \n",
    "        for i in range(len(self.shape)-1):\n",
    "            uli = uli@self.w[i]+self.b[i]\n",
    "            u.append(uli)\n",
    "            a.append(F(uli))\n",
    "\n",
    "        dEdul = (a[-1]-y)*dF(u[-1])\n",
    "        dEdwl = dEdul*np.atleast_2d(a[-2]).T\n",
    "        dEdbl = dEdul\n",
    "\n",
    "        dEdw.append(dEdwl)\n",
    "        dEdb.append(dEdbl)\n",
    "\n",
    "        l = len(self.w)-2\n",
    "        \n",
    "        while l >= 0:\n",
    "            dEdul = np.sum(dEdwl,axis=1)*dF(u[l+1])\n",
    "            dEdwl = dEdul*np.atleast_2d(a[l]).T\n",
    "            dEdbl = dEdul\n",
    "\n",
    "            dEdw.append(dEdwl)\n",
    "            dEdb.append(dEdbl)\n",
    "            \n",
    "            l -= 1\n",
    "        \n",
    "        return dEdw, dEdb\n",
    "        \n",
    "    \n",
    "    def loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        n = y.shape[0]\n",
    "\n",
    "        d = np.array([1/self.nOut*np.sum(np.square(self.predict(xi)-yi)) for xi, yi in zip(x, y)])\n",
    "        \n",
    "        return 1/n*np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('..', '..', 'data', 'iris_csv.csv'))\n",
    "\n",
    "for c in df.columns[0:4]:\n",
    "    df[c] = (df[c]-df[c].mean())/df[c].std()\n",
    "\n",
    "df['synth1'] = df['petallength']*df['petalwidth']\n",
    "df['synth2'] = df['sepallength']*df['petallength']\n",
    "df['synth3'] = df['sepallength']*df['petalwidth']\n",
    "\n",
    "for name in df['class'].unique():\n",
    "    df[f'{name}_label'] = df['class'].map(lambda x: 1 if x == name else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.8\n",
    "\n",
    "p = np.random.permutation(df.index.size)\n",
    "\n",
    "test_size = int(p.size*test_frac)\n",
    "train_size = int(p.size*(1-test_frac))\n",
    "\n",
    "idx_test = p[0 : test_size]\n",
    "idx_train = p[test_size: p.size]\n",
    "\n",
    "features_columns = ['sepallength', 'sepalwidth', 'petallength', 'petalwidth']\n",
    "label_columns = ['Iris-setosa_label', 'Iris-versicolor_label', 'Iris-virginica_label']\n",
    "\n",
    "xTest = np.array(df.iloc[idx_test][features_columns])\n",
    "yTest = np.array(df.iloc[idx_test][label_columns])\n",
    "\n",
    "xTrain = np.array(df.iloc[idx_train][features_columns])\n",
    "yTrain = np.array(df.iloc[idx_train][label_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained loss:  0.42361601776372343\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,4) (4,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# print(len(model.w), [w.shape for w in model.w])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print(len(model.b), [b.shape for b in model.b])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39muntrained loss: \u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m.\u001b[39mloss(xTest, yTest))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(xTrain, yTrain, lr, batch_size, max_iter)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrained loss: \u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m.\u001b[39mloss(xTest, yTest))\n",
      "\u001b[1;32m/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m         dwh[j] \u001b[39m=\u001b[39m dwl\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw)):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw[j] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m lr\u001b[39m*\u001b[39mdwh[j]\n\u001b[1;32m    <a href='vscode-notebook-cell:/mnt/320A41F00A41B221/Data/Development/JupyterLab/neuralNetworks/neuralNetworkClassifier/deep_nn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     dwh[j] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,4) (4,3) "
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 10\n",
    "max_iter = 100\n",
    "\n",
    "layers_shape = (4, 3)\n",
    "\n",
    "model = NNClassifier(layers_shape)\n",
    "\n",
    "# print(len(model.w), [w.shape for w in model.w])\n",
    "# print(len(model.b), [b.shape for b in model.b])\n",
    "\n",
    "print('untrained loss: ', model.loss(xTest, yTest))\n",
    "\n",
    "model.train(xTrain, yTrain, lr, batch_size, max_iter)\n",
    "\n",
    "print('trained loss: ', model.loss(xTest, yTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
