{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def F(x: np.ndarray) -> float:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def dF(x: np.ndarray) -> float:\n",
    "    return F(x)*(1-F(x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def F_jit(x: np.ndarray) -> float | np.ndarray:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def dF_jit(x: np.ndarray) -> float | np.ndarray:\n",
    "    return F_jit(x)*(1-F_jit(x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def grads(xBatch: np.ndarray, yBatch: np.ndarray, w: np.ndarray, b: np.ndarray) -> tuple[np.ndarray]:\n",
    "    n = xBatch.shape[0]\n",
    "    nOut = w.shape[1]\n",
    "\n",
    "    dw = np.zeros(w.shape)\n",
    "    db = np.zeros(b.shape)\n",
    "    \n",
    "    for i in prange(n):\n",
    "        u = np.dot(xBatch[i], w)+b\n",
    "        a = F_jit(u)\n",
    "\n",
    "        dEdu = 2/nOut*(a-yBatch[i])*dF_jit(u)\n",
    "        dw += dEdu*np.atleast_2d(xBatch[i]).T\n",
    "        db += dEdu\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self, nIn: int, nOut: int) -> None:\n",
    "        self.nIn = nIn\n",
    "        self.nOut = nOut\n",
    "        self.w: np.ndarray = np.random.uniform(-1, 1, (nIn, nOut))\n",
    "        self.b: np.ndarray = np.zeros((nOut))\n",
    "\n",
    "\n",
    "    def predict(self, x:np.ndarray) -> np.ndarray:\n",
    "        return F(np.dot(x, self.w)+self.b)\n",
    "\n",
    "\n",
    "    def train(self, xTrain: np.ndarray, yTrain: np.ndarray, lr, batch_size, max_iter) -> None:\n",
    "        n = xTrain.shape[0]\n",
    "\n",
    "        for k in range(max_iter):\n",
    "            idxs = np.random.choice(a=np.arange(n), size=batch_size, replace=False)\n",
    "\n",
    "            dw, db = grads(xTrain[idxs], yTrain[idxs], self.w, self.b)\n",
    "            \n",
    "            self.w -= lr*dw\n",
    "            self.b -= lr*db\n",
    "        \n",
    "    \n",
    "    def loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        n = y.shape[0]\n",
    "        \n",
    "        d = np.array([1/self.nOut*np.sum(np.square(self.predict(xi)-yi)) for xi, yi in zip(x, y)])\n",
    "        \n",
    "        return 1/n*np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('..', '..', 'data', 'iris_csv.csv'))\n",
    "\n",
    "for c in df.columns[0:4]:\n",
    "    df[c] = (df[c]-df[c].min())/(df[c].max()-df[c].min())\n",
    "\n",
    "df['synth1'] = df['petallength']*df['petalwidth']\n",
    "df['synth2'] = df['sepallength']*df['petallength']\n",
    "df['synth3'] = df['sepallength']*df['petalwidth']\n",
    "\n",
    "for name in df['class'].unique():\n",
    "    df[f'{name}_label'] = df['class'].map(lambda x: 1 if x == name else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.8\n",
    "\n",
    "p = np.random.permutation(df.index.size)\n",
    "\n",
    "test_size = int(p.size*test_frac)\n",
    "train_size = int(p.size*(1-test_frac))\n",
    "\n",
    "idx_test = p[0 : test_size]\n",
    "idx_train = p[test_size: p.size]\n",
    "\n",
    "features_columns = ['sepallength', 'sepalwidth', 'synth1']\n",
    "label_columns = ['Iris-setosa_label', 'Iris-versicolor_label', 'Iris-virginica_label']\n",
    "\n",
    "xTest = np.array(df.iloc[idx_test][features_columns])\n",
    "yTest = np.array(df.iloc[idx_test][label_columns])\n",
    "\n",
    "xTrain = np.array(df.iloc[idx_train][features_columns])\n",
    "yTrain = np.array(df.iloc[idx_train][label_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained loss:  0.2761\n",
      "trained loss:  0.057\n"
     ]
    }
   ],
   "source": [
    "nIn = 3\n",
    "nOut = 3\n",
    "\n",
    "learning_rate = 1e-1\n",
    "batch_size = 10\n",
    "max_iter = 15000\n",
    "\n",
    "model = NNClassifier(nIn, nOut)\n",
    "\n",
    "print('untrained loss: ', model.loss(xTest, yTest).round(4))\n",
    "\n",
    "model.train(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    max_iter\n",
    ")\n",
    "\n",
    "print('trained loss: ', model.loss(xTest, yTest).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.933   9.135  -2.178]\n",
      " [  9.439 -12.093  -3.071]\n",
      " [ -8.296 -11.285  17.356]]\n",
      "[-1.087  3.777 -4.947]\n"
     ]
    }
   ],
   "source": [
    "print(model.w.round(3))\n",
    "print(model.b.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
