{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x: np.ndarray) -> float:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def Sigmoid_jit(x: np.ndarray) -> float | np.ndarray:\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def dSigmoid(x: np.ndarray) -> float | np.ndarray:\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y*(1-y)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def grads(xBatch: np.ndarray, yBatch: np.ndarray, w: np.ndarray, b: np.ndarray) -> tuple[np.ndarray]:\n",
    "    n = xBatch.shape[0]\n",
    "\n",
    "    dw = np.zeros(w.shape)\n",
    "    db = np.zeros(b.shape)\n",
    "    \n",
    "    for i in prange(n):\n",
    "        y = Sigmoid_jit(xBatch[i] @ w + b)\n",
    "        dw += (y - yBatch[i]) * np.atleast_2d(xBatch[i]).T\n",
    "        db += y - yBatch[i]\n",
    "    \n",
    "    return (dw, db)\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, nIn: int, nOut: int) -> None:\n",
    "        self.nIn = nIn\n",
    "        self.nOut = nOut\n",
    "        self.w: np.ndarray = np.random.uniform(-1, 1, (nIn, nOut))\n",
    "        self.b: np.ndarray = np.zeros((nOut))\n",
    "\n",
    "    def predict(self, x:np.ndarray) -> np.ndarray:\n",
    "        return Sigmoid(x @ self.w + self.b)\n",
    "\n",
    "    def train(self, xTrain: np.ndarray, yTrain: np.ndarray, lr, batch_size, max_iter) -> None:\n",
    "        n = xTrain.shape[0]\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            idxs = np.random.choice(a=np.arange(n), size=batch_size, replace=False)\n",
    "\n",
    "            dw, db = grads(xTrain[idxs], yTrain[idxs], self.w, self.b)\n",
    "            \n",
    "            self.w -= lr*dw\n",
    "            self.b -= lr*db\n",
    "\n",
    "    def loss(self, x: np.ndarray, y: np.ndarray) -> float:        \n",
    "        Ypred = np.array([self.predict(xi) for xi in x])\n",
    "        h = - 1/self.nOut * np.sum(np.array(y*np.log(Ypred)+(1-y)*np.log(1-Ypred)), axis=1)\n",
    "        return 1/y.shape[0] * np.sum(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('..', '..', 'data', 'iris_csv.csv'))\n",
    "\n",
    "for c in df.columns[0:4]:\n",
    "    df[c] = (df[c]-df[c].mean())/df[c].std()\n",
    "\n",
    "df['synth1'] = df['petallength']*df['petalwidth']\n",
    "df['synth2'] = df['sepallength']*df['petallength']\n",
    "df['synth3'] = df['sepallength']*df['petalwidth']\n",
    "\n",
    "for name in df['class'].unique():\n",
    "    df[f'label-{name}'] = df['class'].map(lambda x: 1 if x == name else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_frac = 0.8\n",
    "\n",
    "# np.random.seed(0)\n",
    "# p = np.random.permutation(df.index.size)\n",
    "\n",
    "# test_size = int(p.size*test_frac)\n",
    "# train_size = int(p.size*(1-test_frac))\n",
    "\n",
    "# idx_test = p[0 : test_size]\n",
    "# idx_train = p[test_size: p.size]\n",
    "\n",
    "# feature_columns = ['sepallength', 'sepalwidth', 'petallength', 'petalwidth']\n",
    "# label_columns = ['label-Iris-setosa', 'label-Iris-versicolor', 'label-Iris-virginica']\n",
    "\n",
    "# xTest = np.array(df.iloc[idx_test][feature_columns])\n",
    "# yTest = np.array(df.iloc[idx_test][label_columns])\n",
    "\n",
    "# xTrain = np.array(df.iloc[idx_train][feature_columns])\n",
    "# yTrain = np.array(df.iloc[idx_train][label_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "setosa_idxs = np.arange(0, 50)\n",
    "versicolor_idxs = np.arange(50, 100)\n",
    "virginica_idxs = np.arange(100, 150)\n",
    "\n",
    "p = np.random.permutation(np.arange(50))\n",
    "\n",
    "setosa_train_idxs = setosa_idxs[p[0:10]]\n",
    "setosa_test_idxs = setosa_idxs[p[10:]]\n",
    "\n",
    "versicolor_train_idxs = versicolor_idxs[p[0:10]]\n",
    "versicolor_test_idxs = versicolor_idxs[p[10:]]\n",
    "\n",
    "virginica_train_idxs = virginica_idxs[p[0:10]]\n",
    "virginica_test_idxs = virginica_idxs[p[10:]]\n",
    "\n",
    "feature_columns = ['sepallength', 'sepalwidth', 'petallength', 'petalwidth']\n",
    "label_columns = ['label-Iris-setosa', 'label-Iris-versicolor', 'label-Iris-virginica']\n",
    "\n",
    "xTrain = np.vstack([\n",
    "    df.iloc[setosa_train_idxs][feature_columns],\n",
    "    df.iloc[versicolor_train_idxs][feature_columns],\n",
    "    df.iloc[virginica_train_idxs][feature_columns]\n",
    "])\n",
    "\n",
    "yTrain = np.vstack([\n",
    "    df.iloc[setosa_train_idxs][label_columns],\n",
    "    df.iloc[versicolor_train_idxs][label_columns],\n",
    "    df.iloc[virginica_train_idxs][label_columns]\n",
    "])\n",
    "\n",
    "xTest = np.vstack([\n",
    "    df.iloc[setosa_test_idxs][feature_columns],\n",
    "    df.iloc[versicolor_test_idxs][feature_columns],\n",
    "    df.iloc[virginica_test_idxs][feature_columns]\n",
    "])\n",
    "\n",
    "yTest = np.vstack([\n",
    "    df.iloc[setosa_test_idxs][label_columns],\n",
    "    df.iloc[versicolor_test_idxs][label_columns],\n",
    "    df.iloc[virginica_test_idxs][label_columns]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained loss:  0.977\n",
      "trained loss:  0.216\n"
     ]
    }
   ],
   "source": [
    "nIn = 4\n",
    "nOut = 3\n",
    "\n",
    "learning_rate = 1e-2\n",
    "batch_size = 20\n",
    "max_iter = 3000\n",
    "\n",
    "model = Perceptron(nIn, nOut)\n",
    "\n",
    "print('untrained loss: ', model.loss(xTest, yTest).round(3))\n",
    "\n",
    "model.train(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    max_iter\n",
    ")\n",
    "\n",
    "print('trained loss: ', model.loss(xTest, yTest).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.01 0.  ] [1 0 0]\n",
      "[1.   0.09 0.  ] [1 0 0]\n",
      "[1.   0.06 0.  ] [1 0 0]\n",
      "[1.   0.28 0.  ] [1 0 0]\n",
      "[1.   0.03 0.  ] [1 0 0]\n",
      "[1.  0.1 0. ] [1 0 0]\n",
      "[1.   0.01 0.  ] [1 0 0]\n",
      "[1.   0.16 0.  ] [1 0 0]\n",
      "[1.   0.04 0.  ] [1 0 0]\n",
      "[1.   0.22 0.  ] [1 0 0]\n",
      "[1. 0. 0.] [1 0 0]\n",
      "[1.   0.26 0.  ] [1 0 0]\n",
      "[1.   0.03 0.  ] [1 0 0]\n",
      "[1.   0.01 0.  ] [1 0 0]\n",
      "[1.   0.15 0.  ] [1 0 0]\n",
      "[1.   0.12 0.  ] [1 0 0]\n",
      "[1.   0.02 0.  ] [1 0 0]\n",
      "[1.   0.32 0.  ] [1 0 0]\n",
      "[1.   0.23 0.  ] [1 0 0]\n",
      "[1.   0.28 0.  ] [1 0 0]\n",
      "[1.   0.02 0.  ] [1 0 0]\n",
      "[1.   0.04 0.  ] [1 0 0]\n",
      "[1.   0.04 0.  ] [1 0 0]\n",
      "[1.  0.1 0. ] [1 0 0]\n",
      "[1.   0.21 0.  ] [1 0 0]\n",
      "[1.  0.3 0. ] [1 0 0]\n",
      "[1.   0.28 0.  ] [1 0 0]\n",
      "[1.   0.24 0.  ] [1 0 0]\n",
      "[1.   0.07 0.  ] [1 0 0]\n",
      "[1.   0.06 0.  ] [1 0 0]\n",
      "[1.   0.04 0.  ] [1 0 0]\n",
      "[1.   0.02 0.  ] [1 0 0]\n",
      "[1.   0.03 0.  ] [1 0 0]\n",
      "[1.   0.28 0.  ] [1 0 0]\n",
      "[1.  0.1 0. ] [1 0 0]\n",
      "[1.   0.05 0.  ] [1 0 0]\n",
      "[1.   0.24 0.  ] [1 0 0]\n",
      "[1.   0.06 0.  ] [1 0 0]\n",
      "[1.   0.16 0.  ] [1 0 0]\n",
      "[1.   0.04 0.  ] [1 0 0]\n",
      "[0.   0.77 0.43] [0 1 0]\n",
      "[0.01 0.13 0.55] [0 1 0]\n",
      "[0.   0.64 0.01] [0 1 0]\n",
      "[0.01 0.48 0.47] [0 1 0]\n",
      "[0.   0.79 0.01] [0 1 0]\n",
      "[0.08 0.75 0.  ] [0 1 0]\n",
      "[0.03 0.23 0.  ] [0 1 0]\n",
      "[0.02 0.57 0.01] [0 1 0]\n",
      "[0.09 0.41 0.  ] [0 1 0]\n",
      "[0.03 0.63 0.  ] [0 1 0]\n",
      "[0.   0.26 0.01] [0 1 0]\n",
      "[0.01 0.81 0.  ] [0 1 0]\n",
      "[0.01 0.57 0.  ] [0 1 0]\n",
      "[0.01 0.44 0.32] [0 1 0]\n",
      "[0.   0.68 0.  ] [0 1 0]\n",
      "[0.   0.18 0.94] [0 1 0]\n",
      "[0.04 0.78 0.  ] [0 1 0]\n",
      "[0.  0.6 0. ] [0 1 0]\n",
      "[0.   0.64 0.04] [0 1 0]\n",
      "[0.   0.33 0.01] [0 1 0]\n",
      "[0.   0.74 0.03] [0 1 0]\n",
      "[0.01 0.83 0.  ] [0 1 0]\n",
      "[0.   0.87 0.01] [0 1 0]\n",
      "[0.01 0.53 0.01] [0 1 0]\n",
      "[0.   0.22 0.07] [0 1 0]\n",
      "[0.   0.92 0.  ] [0 1 0]\n",
      "[0.   0.84 0.  ] [0 1 0]\n",
      "[0.   0.47 0.  ] [0 1 0]\n",
      "[0.   0.2  0.38] [0 1 0]\n",
      "[0.   0.84 0.  ] [0 1 0]\n",
      "[0.   0.32 0.04] [0 1 0]\n",
      "[0.   0.41 0.  ] [0 1 0]\n",
      "[0.01 0.79 0.  ] [0 1 0]\n",
      "[0.01 0.46 0.05] [0 1 0]\n",
      "[0.   0.69 0.01] [0 1 0]\n",
      "[0.01 0.53 0.02] [0 1 0]\n",
      "[0.   0.78 0.  ] [0 1 0]\n",
      "[0.   0.31 0.01] [0 1 0]\n",
      "[0.  0.5 0. ] [0 1 0]\n",
      "[0.01 0.66 0.01] [0 1 0]\n",
      "[0.   0.76 0.13] [0 0 1]\n",
      "[0.   0.2  0.99] [0 0 1]\n",
      "[0.   0.33 0.65] [0 0 1]\n",
      "[0.   0.97 0.16] [0 0 1]\n",
      "[0.   0.81 1.  ] [0 0 1]\n",
      "[0.   0.85 0.8 ] [0 0 1]\n",
      "[0.   0.09 1.  ] [0 0 1]\n",
      "[0.   0.06 1.  ] [0 0 1]\n",
      "[0.   0.05 1.  ] [0 0 1]\n",
      "[0.   0.77 0.21] [0 0 1]\n",
      "[0.   0.06 1.  ] [0 0 1]\n",
      "[0.   0.73 0.78] [0 0 1]\n",
      "[0.   0.33 1.  ] [0 0 1]\n",
      "[0.   0.54 0.89] [0 0 1]\n",
      "[0.   0.52 0.97] [0 0 1]\n",
      "[0.  0.1 1. ] [0 0 1]\n",
      "[0.   0.15 1.  ] [0 0 1]\n",
      "[0.   0.88 0.69] [0 0 1]\n",
      "[0.   0.5  0.98] [0 0 1]\n",
      "[0.   0.58 0.86] [0 0 1]\n",
      "[0.   0.66 0.99] [0 0 1]\n",
      "[0.   0.17 1.  ] [0 0 1]\n",
      "[0.   0.08 1.  ] [0 0 1]\n",
      "[0.   0.42 0.95] [0 0 1]\n",
      "[0.   0.52 0.97] [0 0 1]\n",
      "[0.   0.22 0.98] [0 0 1]\n",
      "[0.   0.5  0.94] [0 0 1]\n",
      "[0.   0.18 1.  ] [0 0 1]\n",
      "[0.   0.66 0.88] [0 0 1]\n",
      "[0.   0.42 0.57] [0 0 1]\n",
      "[0.   0.05 1.  ] [0 0 1]\n",
      "[0.   0.28 0.99] [0 0 1]\n",
      "[0.   0.93 0.05] [0 0 1]\n",
      "[0.   0.03 1.  ] [0 0 1]\n",
      "[0.   0.14 0.98] [0 0 1]\n",
      "[0.   0.5  0.72] [0 0 1]\n",
      "[0.   0.69 0.93] [0 0 1]\n",
      "[0.  0.1 1. ] [0 0 1]\n",
      "[0.   0.21 0.97] [0 0 1]\n",
      "[0.   0.04 1.  ] [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(xTest, yTest):\n",
    "    print(model.predict(x).round(2), y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
